{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8300140,"sourceType":"datasetVersion","datasetId":4930930}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Test pipeline to convert SVG to DST(csv) file ","metadata":{}},{"cell_type":"markdown","source":"Preprocess the dataset:\n1. Convert all svg tags to path tags\n2. convert all curves and to cubic bezier curves\n3. Train a model to predict the DST file from the SVG file","metadata":{}},{"cell_type":"markdown","source":"Preprocess the dataset: done separately for now","metadata":{}},{"cell_type":"code","source":"import pickle\nfrom tqdm import tqdm\nfrom transformers import BartTokenizer, BartForConditionalGeneration, AdamW\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:03:29.995209Z","iopub.execute_input":"2024-05-13T11:03:29.995880Z","iopub.status.idle":"2024-05-13T11:03:36.283500Z","shell.execute_reply.started":"2024-05-13T11:03:29.995844Z","shell.execute_reply":"2024-05-13T11:03:36.282559Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Determine the computing device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:03:36.285297Z","iopub.execute_input":"2024-05-13T11:03:36.285748Z","iopub.status.idle":"2024-05-13T11:03:36.343164Z","shell.execute_reply.started":"2024-05-13T11:03:36.285722Z","shell.execute_reply":"2024-05-13T11:03:36.342469Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# File paths for data\nsvg_paths_file = \"/kaggle/input/initial-data/svg_paths.pkl\"\nstitches_file = \"/kaggle/input/initial-data/stitches.pkl\"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:03:36.346518Z","iopub.execute_input":"2024-05-13T11:03:36.348713Z","iopub.status.idle":"2024-05-13T11:03:36.353489Z","shell.execute_reply.started":"2024-05-13T11:03:36.348684Z","shell.execute_reply":"2024-05-13T11:03:36.352831Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load SVG paths and stitches data\nwith open(svg_paths_file, 'rb') as file:\n    svg_paths = pickle.load(file)\n\nwith open(stitches_file, 'rb') as file:\n    stitches = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:03:36.357052Z","iopub.execute_input":"2024-05-13T11:03:36.359047Z","iopub.status.idle":"2024-05-13T11:03:36.420853Z","shell.execute_reply.started":"2024-05-13T11:03:36.359021Z","shell.execute_reply":"2024-05-13T11:03:36.419982Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load BART tokenizer and model, specify device directly in the model\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-large', device_map='auto',use_cache=True)\n#model = torch.nn.DataParallel(model)  # DataParallel usage\n#model.to(device)  # Ensure model is sent to device","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:03:50.539194Z","iopub.execute_input":"2024-05-13T11:03:50.539556Z","iopub.status.idle":"2024-05-13T11:04:00.575722Z","shell.execute_reply.started":"2024-05-13T11:03:50.539526Z","shell.execute_reply":"2024-05-13T11:04:00.574877Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a037a462d124d1494b2003c5607278d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df27034a67a40ada28885d5e0905db5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78717f60169f48448951999ee0bf194a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6f82c0b1974024802a40fbe025ba17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9fd4d100584c0e838918a0f8d7ecf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0a9c39f665e49afac72053807cc824b"}},"metadata":{}}]},{"cell_type":"code","source":"# Setup for training\noptimizer = AdamW(model.parameters(), lr=5e-5)\nnum_epochs = 30\nbatch_size = 1","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:04:09.761685Z","iopub.execute_input":"2024-05-13T11:04:09.762275Z","iopub.status.idle":"2024-05-13T11:04:09.772307Z","shell.execute_reply.started":"2024-05-13T11:04:09.762243Z","shell.execute_reply":"2024-05-13T11:04:09.771314Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\n# Set CUDA_LAUNCH_BLOCKING to 1 for detailed debugging\nos.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n\ndef check_inputs(tensor, name=\"Tensor\"):\n    if torch.isnan(tensor).any():\n        print(f\"NaN found in {name}\")\n    if torch.isinf(tensor).any():\n        print(f\"Inf found in {name}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:04:11.696539Z","iopub.execute_input":"2024-05-13T11:04:11.697220Z","iopub.status.idle":"2024-05-13T11:04:11.702317Z","shell.execute_reply.started":"2024-05-13T11:04:11.697188Z","shell.execute_reply":"2024-05-13T11:04:11.701464Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    total_loss = 0\n\n    # Processing batches\n    for i in range(0, len(svg_paths), batch_size):\n        batch_svg_paths = svg_paths[i:i+batch_size]\n        batch_stitches = stitches[i:i+batch_size]\n\n        # Prepare inputs and labels with padding and attention mask\n        inputs = tokenizer(batch_svg_paths, return_tensors='pt', padding=True, truncation=True)\n        labels = tokenizer(batch_stitches, return_tensors='pt', padding=True, truncation=True)\n        \n        input_ids = inputs.input_ids.to(device)\n        attention_mask = inputs.attention_mask.to(device)\n        labels = labels.input_ids.to(device)\n\n        # Forward and backward passes\n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    # Calculate average loss\n    average_loss = total_loss / len(svg_paths)\n    print(f\"Epoch {epoch+1}: Average Loss = {average_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:04:27.317284Z","iopub.execute_input":"2024-05-13T11:04:27.318093Z","iopub.status.idle":"2024-05-13T12:01:48.412037Z","shell.execute_reply.started":"2024-05-13T11:04:27.318060Z","shell.execute_reply":"2024-05-13T12:01:48.411309Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"  0%|          | 0/30 [00:00<?, ?it/s]2024-05-13 11:04:29.983656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 11:04:29.983754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 11:04:30.090127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n  3%|▎         | 1/30 [02:01<58:37, 121.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Average Loss = 1.8375477259702022\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 2/30 [03:56<54:50, 117.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Average Loss = 1.2699277542605258\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 3/30 [05:50<52:19, 116.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Average Loss = 1.1369614854897603\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 4/30 [07:45<50:08, 115.71s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Average Loss = 1.0515003635151552\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 5/30 [09:40<48:02, 115.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Average Loss = 1.3484264181392027\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 6/30 [11:34<45:59, 114.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Average Loss = 1.5819290345258052\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 7/30 [13:29<44:01, 114.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Average Loss = 1.1481074336731787\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 8/30 [15:23<42:03, 114.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Average Loss = 1.0481185883578688\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 9/30 [17:18<40:07, 114.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Average Loss = 0.9545038371983141\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 10/30 [19:12<38:11, 114.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Average Loss = 0.9659211228389551\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 11/30 [21:07<36:15, 114.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Average Loss = 0.8711006670895189\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 12/30 [23:01<34:21, 114.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Average Loss = 0.9312799921130189\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 13/30 [24:56<32:27, 114.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Average Loss = 0.8518981308040052\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 14/30 [26:50<30:32, 114.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Average Loss = 0.8205455417680269\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 15/30 [28:45<28:37, 114.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Average Loss = 0.7376106602720695\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 16/30 [30:39<26:42, 114.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Average Loss = 0.7529240303700513\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 17/30 [32:33<24:47, 114.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Average Loss = 0.6641056667460074\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 18/30 [34:28<22:53, 114.47s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Average Loss = 0.6318176456607214\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 19/30 [36:22<20:59, 114.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Average Loss = 0.6472507443758521\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 20/30 [38:17<19:04, 114.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Average Loss = 0.6173898161637901\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 21/30 [40:11<17:09, 114.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Average Loss = 0.5500604200481188\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 22/30 [42:05<15:15, 114.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Average Loss = 0.5134081465773063\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 23/30 [44:00<13:20, 114.39s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Average Loss = 0.5162343934620961\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 24/30 [45:54<11:26, 114.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Average Loss = 0.6226215569099577\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 25/30 [47:49<09:32, 114.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Average Loss = 0.5952019602945535\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 26/30 [49:43<07:37, 114.38s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Average Loss = 1.323385282465727\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 27/30 [51:37<05:43, 114.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Average Loss = 0.7954807311001391\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 28/30 [53:32<03:48, 114.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Average Loss = 0.6278668866299166\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 29/30 [55:26<01:54, 114.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Average Loss = 0.6141275683842083\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [57:21<00:00, 114.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Average Loss = 0.7101094433576753\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.save(model,\"/kaggle/working/bartV5.pth\")\ntorch.save(model.state_dict(), '/kaggle/working/bartV6.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:20:02.282748Z","iopub.execute_input":"2024-05-13T12:20:02.283574Z","iopub.status.idle":"2024-05-13T12:20:04.311606Z","shell.execute_reply.started":"2024-05-13T12:20:02.283541Z","shell.execute_reply":"2024-05-13T12:20:04.310606Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ntorch.cuda.synchronize()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:19:17.996490Z","iopub.execute_input":"2024-05-13T12:19:17.996810Z","iopub.status.idle":"2024-05-13T12:19:18.069908Z","shell.execute_reply.started":"2024-05-13T12:19:17.996786Z","shell.execute_reply":"2024-05-13T12:19:18.068921Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Testing the model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:26:48.347372Z","iopub.execute_input":"2024-05-13T12:26:48.347859Z","iopub.status.idle":"2024-05-13T12:26:54.207803Z","shell.execute_reply.started":"2024-05-13T12:26:48.347809Z","shell.execute_reply":"2024-05-13T12:26:54.207070Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\n# Set CUDA_LAUNCH_BLOCKING to 1 for detailed debugging\nos.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n\ndef check_inputs(tensor, name=\"Tensor\"):\n    if torch.isnan(tensor).any():\n        print(f\"NaN found in {name}\")\n    if torch.isinf(tensor).any():\n        print(f\"Inf found in {name}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:26:54.209634Z","iopub.execute_input":"2024-05-13T12:26:54.210411Z","iopub.status.idle":"2024-05-13T12:26:54.215619Z","shell.execute_reply.started":"2024-05-13T12:26:54.210368Z","shell.execute_reply":"2024-05-13T12:26:54.214565Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:26:54.216743Z","iopub.execute_input":"2024-05-13T12:26:54.217071Z","iopub.status.idle":"2024-05-13T12:26:54.270794Z","shell.execute_reply.started":"2024-05-13T12:26:54.217041Z","shell.execute_reply":"2024-05-13T12:26:54.269919Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"modelTest = BartForConditionalGeneration.from_pretrained('facebook/bart-large', device_map='auto',use_cache=True)\n# modelTest.load_state_dict(\"/kaggle/working/bartV6.pth\")\n# Load the saved state dictionary\nstate_dict = torch.load(\"/kaggle/working/bartV6.pth\")\n\n# Load the state dictionary into the model\nmodelTest.load_state_dict(state_dict)\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:26:54.273162Z","iopub.execute_input":"2024-05-13T12:26:54.273562Z","iopub.status.idle":"2024-05-13T12:27:05.817146Z","shell.execute_reply.started":"2024-05-13T12:26:54.273530Z","shell.execute_reply":"2024-05-13T12:27:05.816145Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90108919e7c149a784ee3a88f29e91a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85cb861ed6cd4d9cbb919e9e4cba932e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a76d1f52a34006876fb3e8b0166517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b040a5ac863a4f5f95819726e4265236"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6657555ba5347ae85cc501b8d289ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f809f6b6f31b4b2a8a17f81aa081f19a"}},"metadata":{}}]},{"cell_type":"code","source":"test_input = \"M 0.06 12.57 C 0.06 12.57 30.62 12.57 30.62 12.57 C 30.62 12.57 0.07 63.25 0.07 63.25 C 0.07 63.25 0 63.37 0 63.37 C 0 63.37 0.07 74.2 0.07 74.2 C 0.07 74.2 43.9 74.2 43.9 74.2 C 43.9 74.2 43.9 63.04 43.9 63.04 C 43.9 63.04 13.02 63.04 13.02 63.04 C 13.02 63.04 43.9 12.21 43.9 12.21 C 43.9 12.21 43.9 1.41 43.9 1.41 C 43.9 1.41 0.06 1.41 0.06 1.41 C 0.06 1.41 0.06 12.57 0.06 12.57 C 0.06 12.57 0.06 12.57 0.06 12.57 M 54.2 74.2 C 54.2 74.2 94.62 74.2 94.62 74.2 C 94.62 74.2 94.62 63.04 94.62 63.04 C 94.62 63.04 65.36 63.04 65.36 63.04 C 65.36 63.04 65.36 43.34 65.36 43.34 C 65.36 43.34 91.1 43.34 91.1 43.34 C 91.1 43.34 91.1 32.17 91.1 32.17 C 91.1 32.17 65.36 32.17 65.36 32.17 C 65.36 32.17 65.36 12.57 65.36 12.57 C 65.36 12.57 94.62 12.57 94.62 12.57 C 94.62 12.57 94.62 1.41 94.62 1.41 C 94.62 1.41 54.2 1.41 54.2 1.41 C 54.2 1.41 54.2 74.2 54.2 74.2 C 54.2 74.2 54.2 74.2 54.2 74.2 M 129.28 1.41 C 129.28 1.41 104.14 1.41 104.14 1.41 C 104.14 1.41 104.14 74.2 104.14 74.2 C 104.14 74.2 115.3 74.2 115.3 74.2 C 115.3 74.2 115.3 12.57 115.3 12.57 C 115.3 12.57 129.27 12.57 129.27 12.57 C 132.15 12.57 135.01000000000002 13.8 137.79000000000002 16.22 C 140.54000000000002 18.619999999999997 141.94000000000003 21.83 141.94000000000003 25.74 C 141.94000000000003 30.049999999999997 140.52000000000004 33.35 137.71000000000004 35.55 C 134.86000000000004 37.779999999999994 132.47000000000003 38.91 130.58000000000004 38.91 C 130.58000000000004 38.91 117.29000000000005 39.019999999999996 117.29000000000005 39.019999999999996 C 117.29000000000005 39.019999999999996 135.40000000000003 74.19999999999999 135.40000000000003 74.19999999999999 C 135.40000000000003 74.19999999999999 148.19000000000003 74.19999999999999 148.19000000000003 74.19999999999999 C 148.19000000000003 74.19999999999999 134.94000000000003 48.89999999999999 134.94000000000003 48.89999999999999 C 140.76000000000002 47.419999999999995 145.23000000000002 44.54999999999999 148.23000000000002 40.35999999999999 C 151.33 36.03999999999999 152.9 31.11999999999999 152.9 25.739999999999995 C 152.9 18.999999999999993 150.52 13.189999999999994 145.82 8.489999999999995 C 141.12 3.7899999999999947 135.54999999999998 1.399999999999995 129.28 1.399999999999995 C 129.28 1.399999999999995 129.28 1.41 129.28 1.41 M 221.18 11.11 C 213.81 3.7399999999999993 204.86 0 194.58 0 C 184.3 0 175.25 3.74 167.88000000000002 11.11 C 160.51000000000002 18.48 156.77000000000004 27.46 156.77000000000004 37.81 C 156.77000000000004 48.160000000000004 160.51000000000005 57.14 167.88000000000005 64.51 C 175.25000000000006 71.88000000000001 184.23000000000005 75.62 194.58000000000004 75.62 C 204.93000000000004 75.62 213.89000000000004 71.87 221.23000000000005 64.46000000000001 C 228.57000000000005 57.06000000000001 232.28000000000006 48.09 232.28000000000006 37.81000000000001 C 232.28000000000006 27.530000000000015 228.54000000000005 18.48000000000001 221.17000000000007 11.11000000000001 C 221.17000000000007 11.11000000000001 221.18 11.11 221.18 11.11 M 194.59 64.45 C 187.28 64.45 180.95 61.81 175.76 56.61 C 170.57 51.41 167.94 45.08 167.94 37.81 C 167.94 30.540000000000006 170.57 24.220000000000002 175.76 19.01 C 180.95 13.8 187.28 11.170000000000002 194.58999999999997 11.170000000000002 C 201.89999999999995 11.170000000000002 208.12999999999997 13.810000000000002 213.30999999999997 19.01 C 218.49999999999997 24.220000000000002 221.12999999999997 30.54 221.12999999999997 37.81 C 221.12999999999997 45.080000000000005 218.49999999999997 51.400000000000006 213.30999999999997 56.61 C 208.11999999999998 61.81999999999999 201.81999999999996 64.45 194.58999999999997 64.45 C 194.58999999999997 64.45 194.59 64.45 194.59 64.45 \"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:27:05.818405Z","iopub.execute_input":"2024-05-13T12:27:05.818679Z","iopub.status.idle":"2024-05-13T12:27:05.825210Z","shell.execute_reply.started":"2024-05-13T12:27:05.818656Z","shell.execute_reply":"2024-05-13T12:27:05.824322Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer([test_input], max_length=2048, return_tensors=\"pt\", padding=True, truncation=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:27:05.826417Z","iopub.execute_input":"2024-05-13T12:27:05.826708Z","iopub.status.idle":"2024-05-13T12:27:05.855341Z","shell.execute_reply.started":"2024-05-13T12:27:05.826684Z","shell.execute_reply":"2024-05-13T12:27:05.854469Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"output = modelTest.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, early_stopping=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:27:05.856453Z","iopub.execute_input":"2024-05-13T12:27:05.858358Z","iopub.status.idle":"2024-05-13T12:27:09.059631Z","shell.execute_reply.started":"2024-05-13T12:27:05.858333Z","shell.execute_reply":"2024-05-13T12:27:09.057874Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [62,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [22,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [31,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodelTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1393\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1388\u001b[0m         )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1393\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:503\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    501\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    502\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 503\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1154\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[0;32m-> 1154\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1157\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:135\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    130\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    131\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    132\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    133\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}